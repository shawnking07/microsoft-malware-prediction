# Microsoft Malware Prediction

## COMP9417 Machine Learning Project

[TOC]

### Introduction

Nowadays, the malware industry continues to be a well-organized, well-funded market dedicated to evading traditional security measures. Once a computer is infected by malware, criminals can hurt consumers and enterprises in many ways. For instance, hackers can steal important files and information from compromised computer and even remain virus to cause further damage.

With more than one billion enterprise and consumer customers, Our group takes this problem very seriously and is deeply invested in improving security. We are devoted to predicting if a machine will soon be hit with malware by processing and analyzing the dataset from Microsoft.

### Implementation

We did several baseline tests which are based on different underlying theories. The reason for this is pretty simple - choose a model which performs best and try to improve this model. We had chosen four classifiers from scikit-learn which are based on naive Bayes and decision tree.

During the implementation of the baseline, we've encountered two major issues:

+ The data set is too big
+ There is too much missing value

For the first problem, we tried to perform type conversion. For the missing values, we've implemented several strategies on this. After a series of experiment and failure, we finally figured it out by applying feature engineering on the data set.

#### Reduce memory usage

First, we should focus on the dataset. The data given for this competition is huge. The training set is 4.08GB and the test set is 3.54GB. When use normal ``read_csv()`` function without any preprocess to load the CSV file, it will definitely take really long time and waste much memory space.

Some types imported using `pandas` are not quite right. By manually indicating the type for each feature, the usage of memories can be decreased dramatically.

There are several rules to reduce the ``pandas`` ``DataFrame`` size:

- Load ``object`` dtype as ``categories``
- Load binary value like (0,1) as ``int8``
- ``float64`` can be switched to ``float32`` or ``float16``

To analyze the datatype of each column, we don't need to load the whole dataset. We can use the parameter ``chunksize`` to load a small bunch of data, or transfer our CSV file to [HDF5](https://support.hdfgroup.org/HDF5/whatishdf5.html) which can make it easier for us to use [Vaex](https://github.com/vaexio/vaex) library to do feature learning on our dataset.

#### Baseline and Model Selection

The following shows the result of four classifiers:

```
baseline test using classifier: DecisionTreeClassifier
              precision    recall  f1-score   support

           0       0.61      0.37      0.46   4462591
           1       0.55      0.77      0.64   4458892

    accuracy                           0.57   8921483
   macro avg       0.58      0.57      0.55   8921483
weighted avg       0.58      0.57      0.55   8921483

spend 259.47268295288086 seconds
```

<div align=center> Decision Tree  </div>


```
baseline test using classifier: RandomForestClassifier
              precision    recall  f1-score   support

           0       0.54      0.56      0.55   4462591
           1       0.54      0.52      0.53   4458892

    accuracy                           0.54   8921483
   macro avg       0.54      0.54      0.54   8921483
weighted avg       0.54      0.54      0.54   8921483

spend 710.0533969402313 seconds
```

<div align=center> Random Forest </div>

```
baseline test using classifier: BernoulliNB
              precision    recall  f1-score   support

           0       0.57      0.31      0.40   4462591
           1       0.53      0.77      0.62   4458892

    accuracy                           0.54   8921483
   macro avg       0.55      0.54      0.51   8921483
weighted avg       0.55      0.54      0.51   8921483

spend 306.5881145000458 seconds
```

<div align=center> Bionomial Naive Bayes </div>

```
baseline test using classifier: MultinomialNB
              precision    recall  f1-score   support

           0       0.52      0.53      0.52   4462591
           1       0.52      0.51      0.51   4458892

    accuracy                           0.52   8921483
   macro avg       0.52      0.52      0.52   8921483
weighted avg       0.52      0.52      0.52   8921483

spend 306.5881145000458 seconds
```

<div align=center> Multinomial Naive Bayes </div>

The decision trees are providing better accuracy and it's also the fastest. Thus, our implementation for this project is based on the decision tree.

#### Handling Missing Values

This part was originally derived from the baseline test. During the starting point of the project, we found that simply drop rows with empty values are not acceptable because most rows will be dropped, leading our baseline models to poor accuracy. As a result, finding out a good way of handling the missing values becomes an important part of the project. We've tried many ways and the following content will make an introduction to the methods we've tried and also do some analysis. 

In addition, since our baseline tests are based on four classifiers, there will be four graphs for each method we've been through and this can be very redundant to put them together. In order to keep simplicity, we only list the output of decision trees here. The complete outputs will be put in the Appendix for readers to check out the data if necessary.

#### Fill with constant value

The first idea that comes to our mind is to fill missing values with a placeholder denotes nothing. Based on this idea, we tried `fillna` method provided by `pandas`. We filled -1 to the numerical fields and \'_unknown_\' to those fields required string. And here comes the result:

```
baseline test using classifier: DecisionTreeClassifier
              precision    recall  f1-score   support

           0       0.61      0.37      0.46   4462591
           1       0.55      0.77      0.64   4458892

    accuracy                           0.57   8921483
   macro avg       0.58      0.57      0.55   8921483
weighted avg       0.58      0.57      0.55   8921483

spend 367.41683888435364 seconds
```

<div align=center> Decision Tree  </div>

The accuracy of these models ranges from 0.51 to 0.57. Noticeably, models based on decision tree got a better performance, this is a good reason to go further on the decision tree. However, at this point, the imputed data filled in are noise, the output may vary along with the input data. This can bring a negative impact to our further experiment. To find a reliable baseline text, we need to do more.



#### Using `KNNImputer`

The second idea is to use `imputers` provided by scikit-learn. We tried to apply the`KNNImputer` to our data set because this makes more sense than just fill in some constant values. The data with integer type and float type will be imputed by the `KNNImputer`.

To use of tools provided by scikit-learn, we also need to use encoders as well since there are a lot of strings in the data set. For this project, the `OneHotEncoder` is not suitable. Because the data set passed in is too large, the size of the matrix generated by the `OneHotEncoder` may exceed the maximum size of a `numpy` array. And also, input data is about 4.08 gigs, the `OneHotEncoder` would take more memory usage than other encoders leading to a larger requirement of memory.  Thus, the `LabelEncoder` and `OridinalEncoder` are our available choices. In the baseline test, we choose the `OridinalEncoder`. 

Surprisingly, the imputation of data using the `KNNImputer` can be extremely slow, it is almost impossible to impute all the 4.08 gigs of data. We did not decide to use this as our strategy handling missing data. But failure is a part of the experiment, it is always good to check our work. So, we scaled data and did the assessment. Here are the result of the assessment using 0.5 per cent of the data set:

```
baseline test using classifier: DecisionTreeClassifier
size of the data: (17842, 82) 

              precision    recall  f1-score   support

           0       0.57      0.59      0.58      8868
           1       0.58      0.56      0.57      8974

    accuracy                           0.57     17842
   macro avg       0.57      0.57      0.57     17842
weighted avg       0.58      0.57      0.57     17842

spend 63.54545831680298 seconds
```

<div align=center> Decision Tree  </div>

By contrast, just filling constant values can be way faster.

```
baseline test using classifier: DecisionTreeClassifier
size of the data: (17842, 82) 

              precision    recall  f1-score   support

           0       0.57      0.60      0.58      8868
           1       0.58      0.55      0.57      8974

    accuracy                           0.57     17842
   macro avg       0.57      0.57      0.57     17842
weighted avg       0.57      0.57      0.57     17842

spend 0.6433885097503662 seconds
```

<div align=center> Decision Tree  </div>

#### Feature Engineering

After experienced such failures, we try to do some feature engineering - since some features are incomplete, maybe it is better to remove them rather than keeping them. By expanding the idea above, our new strategy formed, which is to remove some quite unrelated data from the data set. Besides, some features are very confusing with typo and garbles, so we need to correct them by building a string dictionary . It is easy for us to translate similar strings to the same one and make the data more neat and orderly.

##### Drop columns which are mostly missing

```python
sorted([(i,train[i].countna()) for i in train],key=lambda a:a[1], reverse=True)
```

```txt
PuaMode                                           0.9997411865269485
Census_ProcessorClass                             0.9958940682843872
DefaultBrowsersIdentifier                         0.9514163732644001
Census_IsFlightingInternal                        0.8304402978742436
Census_InternalBatteryType                        0.7104680914596823
Census_ThresholdOptIn                             0.635244723326828
Census_IsWIMBootEnabled                           0.6343903810610859
SmartScreen                                       0.35610794752397107
OrganizationIdentifier                            0.3084148677972037
SMode                                             0.0602768620418825
CityIdentifier                                    0.0364747654621995
Wdft_IsGamer                                      0.034013515465982504
Wdft_RegionIdentifier                             0.034013515465982504
Census_InternalBatteryNumberOfCharges             0.030124475941948215
...
```

There are 2 columns **PuaMode** and **Census_ProcessorClass** which have more than 99% of missing values.

##### Drop columns which are mostly same values

By counting the frequency of values in each column, there are 12 categorical columns whose majority category covers more than 99% of occurrences. This can be count by ``value_counts(dropna=True, normalize=True)``. Also, this information is shown on the [kaggle competition page](https://www.kaggle.com/c/microsoft-malware-prediction/data?select=train.csv).

Therefore, these columns below can be removed:

```python
['PuaMode',
 'Census_ProcessorClass',
 'Census_IsWIMBootEnabled',
 'IsBeta',
 'Census_IsFlightsDisabled',
 'Census_IsFlightingInternal',
 'AutoSampleOptIn',
 'Census_ThresholdOptIn',
 'SMode',
 'Census_IsPortableOperatingSystem',
 'PuaMode',
 'Census_DeviceFamily',
 'UacLuaenable',
 'Census_IsVirtualDevice']
```

##### Drop columns which are highly correlated

We can use ``pandas`` ``corr`` and ``pyplot`` to draw a [heatmap](./pics/heatmap.png) about the correlation. Before using ``corr``, it is necessary to transfer categorical features, in this case, we used ``LabelEncoder`` (about choosing encoders, we had a [discussion](#using-knnimputer) on these sklearn built-in methods).

![heatmap](./pics/heatmap.png)

Pickup the dark pixels which have high value in this heatmap, those are highly correlated features. And drop the columns which have fewer unique values.

##### Final result about our dropped features

Based on our feature learning result and referred to others' work, we decided to remove these unuseful columns to save our training time and memory usage.

```python
['PuaMode',
 'Census_ProcessorClass',
 'Census_IsWIMBootEnabled',
 'IsBeta',
 'Census_IsFlightsDisabled',
 'Census_IsFlightingInternal',
 'AutoSampleOptIn',
 'Census_ThresholdOptIn',
 'SMode',
 'Census_IsPortableOperatingSystem',
 'Census_DeviceFamily',
 'UacLuaenable',
 'Census_IsVirtualDevice',
 'Platform',
 'Census_OSSkuName',
 'Census_OSInstallLanguageIdentifier',
 'Processor']
```

##### Translate similar words to the same one
```python
df =data['Census_InternalBatteryType']
data_list = df.values.tolist()
for check in data_list:
    result.append(check if check not in result)

[nan, 'lion', 'li-i', '#', 'lip', 'liio', 'vbox', 'li p', 'real', 'unkn', 'pbac', 'li', 'bq20', 'nimh', '\x04lio', 'lgi0', 'lhp0', 'ithi', 'batt', 'lipp', 'lipo', '4cel', 'ram', 'lit', 'a140', 'bad', 'asmb', 'virt', 'ca48', '4ion', 'd', 'a132',  'cl53', 'lio', 'li-l',  'í\x03-i', '0x0b', 'lgs0', '3ion', 'ots0', 'lai0', 'lilo', 'pa50', 'h4°s', '5nm1', 'li-p', 'lhpo', '0ts0', 'pad0', 'sail', 'p-sn', 'icp3', 'a130', '2337', '\x1f˙˙˙', 'lgl0', 'l\x15', '@i\uf8f5\uf8f5', 'li\x90o', '4lio', 'lp', 'li?', '\x04ion', 'pbso', 'a138', 'li-h', '6ion', '3500', 'h00j', 'li\x10', 'sams', '\x03ip', '8', '#TAB#', 'l\x06&#TAB#']
```
We choose feature "Census_InternalBatteryType" as an example.
As can be seen in the list there are many similar words such as 'lgi0','lgio','lhp0','lhpo','lgl0','lglo'. In fact ,they are miswritten and are divided into diferent categories which should be put in one category. Therefore, we can build a dictionary and translate those confused words to the same key word "lg". Similarly , we classify all words in this method.

However, there is another problem . Some words contain  invalid characters like '@i\uf8f5\uf8f5' , we cannot put such word in the values directly because when computer compiles code in different encoding ways ("utf-8" and "gbk") , It is difficult to find out what those special characters transfer to. Finally, I choose transfer those characters  to empty by using regex. As a result, we can ignore all escape characters.

```python
delete_symbol = re.sub(r'[^a-zA-Z0-9]',"",check)
irregular_forms = {'lion' :['lio','li','lin','lion','lii','4lio','6ion','lilo','lai0','lil0','x04lio','liio','3ion'] ,
                   'lip':['lipp','lipo','lp','lip','l','lil','lit'] ,
                   'TAB':['TAB','lx06TAB'],
                    'lg':['lgi0','lgio','lhp0','lhpo','lgl0','lglo'],
                    'nan':['',' ','unkn','nan','0','o'],
                    'pb':['pbso','pad0','psn','pg5c']}
```
In this case, we truly decrease the number of useless words and make the classification more accurate.

#### Using ``LightGBM``

We used [LightGBM](https://github.com/microsoft/LightGBM) as our training framework for this competition.
> It is a fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART) framework based on decision tree algorithms. [^1]
[^1]: Ke, Guolin, et al. "Lightgbm: A highly efficient gradient boosting decision tree." Advances in neural information processing systems. 2017.

We applied our feature engineering conclusion, dropped some unnecessary and high correlation features. For the Na and missing value part, we just used the LightGBM default method which can make our preprocessing part simpler (the missing value will be ignored during split finding[^2]). For the categorical features, LightGBM could handle them directly, which means encoding part can be left out. But it is not supported in GPU acceleration, we still used ``LabelEncoder`` in my implementation.
[^2]: Kurita, Keita. "LightGBM and XGBoost Explained." Machine Learning Explained, 30 May 2019, mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/.

Due to our limitation of compute resources. We picked a large learning rate 0.5 in this case. For parameters tuning part, there are some rules from LightGBM, in conclusion: tuning small ``learning_rate`` with large ``num_iterations``, setting small ``num_leaves``, using bagging by set ``bagging_fraction`` and ``bagging_freq``. To reduce coding work, we imported ``optuna`` library to automatically running the parameters tuning[^3].
[^3]: Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta,and Masanori Koyama. 2019. "Optuna: A Next-generation Hyperparameter Optimization Framework." In KDD.

![feature importance](./pics/feature-importance.png)

![score](./pics/CleanShot%202020-08-02%20at%2015.33.24@2x.png)

The result looks fine compared with our baseline. We still need a lot of space to improve our model, like a deep feature engineering, some feature values could be cleaned and grouped. Besides, small learning rate can be applied.


### Appendix

